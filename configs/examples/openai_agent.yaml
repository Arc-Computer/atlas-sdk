agent:
  type: litellm
  name: example-openai-agent
  system_prompt: |
    You are a security-focused code reviewer acting as the Atlas Student. Analyze code for vulnerabilities including prompt injection, input validation issues, access control bypasses, and architectural security flaws. Provide specific attack vectors and exploitation examples for each issue identified.
  tools: []
  llm:
    provider: openai
    model: gpt-5-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.2
    max_output_tokens: 16000
    timeout_seconds: 180
  response_format: null

teacher:
  llm:
    provider: openai
    model: gpt-5-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.1
    max_output_tokens: 16000
    timeout_seconds: 180

rim:
  small_model:
    provider: gemini
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 8096
  large_model:
    provider: gemini
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 8096
  judge_prompt: |
    Reward the agent based on security analysis depth and accuracy. Higher scores for:
    - Identifying multiple vulnerability types (prompt injection, input validation, access control)
    - Providing concrete attack vectors and exploitation examples
    - Explaining root causes and architectural issues
    - Suggesting defense-in-depth mitigations
    Lower scores for surface-level analysis that misses critical security flaws.
  variance_threshold: 0.15
  uncertainty_threshold: 0.3

storage:
  database_url: postgresql://atlas:atlas@localhost:5433/atlas
  min_connections: 1
  max_connections: 5
  statement_timeout_seconds: 30

learning:
  llm:
    provider: gemini
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    temperature: 0.1
    max_output_tokens: 8192
    timeout_seconds: 120
  gates:
    enforce_actionability: true
    enforce_cue: true
  # Optional: Tune learning behavior (all have sensible defaults)
  # history_limit: 10          # How many recent runs to review (default: 10)
  # apply_to_prompts: true    # Inject learning into prompts (default: true)
  # pruning_config:            # Tune when entries are pruned based on metrics
  #   min_sessions: 10         # Minimum sessions before pruning (default: 10)
  #   min_cue_hit_rate: 0.05   # Minimum cue hit rate to avoid "too specific" (default: 0.05)
  #   min_reward_delta: 0.01   # Minimum reward improvement to avoid "neutral" (default: 0.01)
  #   min_transfer_sessions: 20 # Sessions needed to check transfer success (default: 20)
